@article{ayadi2011,
  title={Survey on speech emotion recognition: features, classification schemes and database},
  author={Ayadi, Moataz El and Kamel, Mohamed S. and Karray, Fakhri},
  journal={Pattern Recognition},
  volume={44},
  number={3},
  pages={572-587},
  year={2011}
}

@inproceedings{satt2017,
  title={Efficient Emotion Recognition from Speech Using Deep Learning on Spectrograms},
  author = {Satt, Aharon and Rozenberg, Shai and Hoory, Ron},
  booktitle={INTERSPEECH},
  pages={1089-1093},
  year={2017},
}

@article{busso2008,
  title={IEMOCAP: Interactive emotional dyadic motion capture database},
  author={Busso, Carlos and Bulut, Murtaza and Lee, Chi Chun and Kazemzadeh, Abe and Mower, Emily and Kim, Samuel and Chang, Jeannette N. and Lee, Sungbok and Narayanan, Shrikanth S.},
  journal={Journal of Language Resources and Evaluation},
  volume={42},
  number={4},
  pages={335-359},
  year={2008}
}

@inproceedings{ma2017,
  title={Speech Emotion Recognition with Emotion-Pair Based Framework Considering Emotion Distribution Information in Dimensional Emotion Space},
  author={Ma, Xi and Wu, Zhiyong and Jia, Jia and Xu, Mingxing and Meng, Helen and Cai, Lianhong},
  booktitle={INTERSPEECH},
  pages={1238-1242},
  year={2017},
}

@article{busso2009,
  title={Analysis of Emotionally Salient Aspects of Fundamental Frequency for Emotion Detection},
  author={Busso, C. and Lee, Sungbok and Narayanan, S.},
  journal={IEEE Transactions on Audio, Speech, and Language Processing},
  volume={17},
  number={4},
  pages={582-596},
  year={2009}
}

@article{cowie2001,
  title={Emotion recognition in human-computer interaction},
  author={Cowie, Roddy and Douglascowie, Ellen and Tsapatsoulis, Nicolas and Votsis, George and Kollias, Stefanos and Fellenz, Winfried and Taylor, John G},
  journal={IEEE Signal Processing Magazine},
  volume={18},
  number={1},
  pages={32-80},
  year={2001}
}

@article{vayrynen2013,
  title={Classifier-based learning of nonlinear feature manifold for visualization of emotional speech prosody},
  author={Vayrynen, Eero and Kortelainen, J. and Seppanen, Tapio},
  journal={IEEE Transactions on Affective Computing},
  volume={4},
  number={1},
  pages={47-56},
  year={2013}
}

@book{bellanger1978,
  title={Digital processing of speech signals},
  author={Bellanger, M. G},
  publisher={Prentice-Hall},
  pages={118-119},
  year={1978},
}

@article{atal1974,
  title={Effectiveness of linear prediction characteristics of the speech wave for automatic speaker identification and verification},
  author={Atal, B. S.},
  journal={the Journal of the Acoustical Society of America},
  volume={55},
  number={6},
  pages={1304-1312},
  year={1974}
}

@article{davis1980,
  title={Effectiveness of linear prediction characteristics of the speech wave for automatic speaker identification and verification Comparison of parametric representations for monosyllabic word recognition in continuously spoken sentences},
  author={Davis, S. B. and Mermelstein, Paul},
  journal={IEEE Transactions on Acoustics, Speech, and Signal Processing},
  volume={28},
  number={4},
  pages={357-366},
  year={1980}
}

@article{gobl2003,
  title={The role of voice quality in communicating emotion, mood and attitude},
  author={Gobl Christer and Chasaide, Ailbhe N??},
  journal={Speech Communication},
  volume={40},
  number={1-2},
  pages={189-212},
  year={2003}
}

@inproceedings{han2014,
  title={Speech Emotion Recognition Using Deep Neural Network and Extreme Learning Machine},
  author={Han, Kun and Yu, Dong and Tashev, Ivan},
  booktitle={INTERSPEECH},
  year={2014},
}

@inproceedings{lee2015,
  title={High-level Feature Representation using Recurrent Neural Network for Speech Emotion Recognition},
  author={Lee, Jinkyu and Tashev, Ivan},
  booktitle={INTERSPEECH},
  year={2015},
}

@inproceedings{huang2014,
  title={Speech Emotion Recognition Using CNN},
  author={Huang, Zhengwei and Dong, Ming and Mao, Qirong and Zhan, Yongzhao},
  booktitle={Acm International Conference on Multimedia},
  pages={801-804},
  year={2014},
}

@inproceedings{le2013,
  title={Emotion recognition from spontaneous speech using Hidden Markov models with deep belief networks},
  author={Le, Duc and Provost, Emily Mower},
  booktitle={Automatic Speech Recognition and Understanding},
  pages={216-221},
  year={2013},
}

@article{rana2016,
  title={Emotion Classification from Noisy Speech - A Deep Learning Approach},
  author={Rana, Rajib},
  journal={arXiv preprint arXiv:1603.05901},
  year={2016},
}

@article{chernykh2017,
  title={Emotion Recognition From Speech With Recurrent Neural Networks},
  author={Chernykh, Vladimir and Sterling, Grigoriy and Prihodko, Pavel},
  journal={arXiv preprint arXiv:1701.08071},
  year={2017},
}

@inproceedings{jaitly2012,
  title={Learning a better representation of speech soundwaves using restricted boltzmann machines},
  author={Jaitly, Navdeep and Hinton, Geoffrey},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing},
  pages={5884-5887},
  year={2012},
}

@inproceedings{bhargava2015,
  title={Architectures for deep neural network based acoustic models defined over windowed speech waveforms},
  author={Bhargava, Mayank and Rose, Richard},
  booktitle={INTERSPEECH},
  year={2015},
}

@inproceedings{sainath2015a,
  title={Convolutional, Long Short-Term Memory, fully connected Deep Neural Networks},
  author={Sainath, Tara N. and Vinyals, Oriol and Senior, Andrew and Sak, Ha?im},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing},
  pages={4580-4584},
  year={2015},
}

@inproceedings{sainath2015b,
  title={Learning the speech front-end with raw waveform CLDNNs},
  author={Sainath, Tara N. and Weiss, Ron J. and Senior, Andrew W. and Wilson, Kevin W. and Vinyals, Oriol},
  booktitle={INTERSPEECH},
  pages={1-5},
  year={2015},
}

@article{hannun2014,
  title={Deep Speech: Scaling up end-to-end speech recognition},
  author={Hannun, Awni and Case, Carl and Casper, Jared and Catanzaro, Bryan and Diamos, Greg and Elsen, Erich and Prenger, Ryan and Satheesh, Sanjeev and Sengupta, Shubho and Coates, Adam},
  journal={Computer Science},
  year={2014},
}

@article{amodei2015,
  title={Deep Speech 2: End-to-End Speech Recognition in English and Mandarin},
  author={Amodei, Dario and Anubhai, Rishita and Battenberg, Eric and Case, Carl and Casper, Jared and Catanzaro, Bryan and Chen, Jingdong and Chrzanowski, Mike and Coates, Adam and Diamos, Greg},
  journal={Computer Science},
  year={2015},
}

@inproceedings{variani2014,
  title={Deep neural networks for small footprint text-dependent speaker verification},
  author={Variani, Ehsan and Lei, Xin and Mcdermott, Erik and Moreno, Ignacio Lopez and Gonzalez-Dominguez, Javier},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing},
  pages={4052-4056},
  year={2014},
}

@inproceedings{trigeorgis2016,
  title={Adieu features? End-to-end speech emotion recognition using a deep convolutional recurrent network},
  author={Trigeorgis, George and Ringeval, Fabien and Brueckner, Raymond and Marchi, Erik and Nicolaou, Mihalis A. and Schuller, Bj?rn and Zafeiriou, Stefanos},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing},
  year={2016},
}
